#
# System training parameters from phrasal-train-tune.sh
#

# General parameters
HOST=`hostname -s`
MEM=30g
JAVA_OPTS="-server -ea -Xmx${MEM} -Xms${MEM} -XX:+UseParallelGC -XX:PermSize=256m -XX:MaxPermSize=256m"

THREADS_EXTRACT=4
THREADS_DECODE=8

EXTRACTOR_OPTS="-DcustomScores=phi_tf,lex_tf,phi_ft,lex_ft,phrasePenalty,count,uniq"
MERT_OPTS="-DsmoothBLEU=true"
DECODER_OPTS="-DMultiBeamDecoderDebug=true -DSRILM=true -Djava.library.path=/scr/nlp/data/gale3/SRILM-JNI/${HOST}"

# Resource locations
REFDIR=/scr/nlp/data/gale/AE-MT-eval-data
SCRIPTDIR=${JAVANLP_HOME}/projects/mt/scripts-private

# Phrase extraction parameters (steps 1 and 5)
CORPUSDIR=/scr/nlp/data/gale3/NIST09/align/merged
CORPUS_SRC=${CORPUSDIR}/good_subset/corpus.ar
CORPUS_TGT=${CORPUSDIR}/good_subset/corpus.en
CORPUS_ALIGN=${CORPUSDIR}/good_subset/corpus.align
LINES=90000000
ALIGN=grow-diag
MAX_PHRASE_LEN=7
# Minimum p(e|f) probability for a rule
MIN_PHRASE_SCORE=1e-4

# In how many chunks to split phrase extraction. Setting the
# value to X makes phrase extraction run X times slower,
# though one needs about X times less memory.
# Note: "split" means we split the dev/test-set phrases to score
# into X chunks, and make 1-2 passes over the training data
# for each one of them.
# (if you run out of memory, increase the split value)
SPLIT="-split 2"

EXTRACTORS=edu.stanford.nlp.mt.train.MosesPharoahFeatureExtractor:edu.stanford.nlp.mt.train.CountFeatureExtractor:edu.stanford.nlp.mt.train.LexicalReorderingFeatureExtractor

LO_ARGS="-hierarchicalOrientationModel true -orientationModelType msd2-bidirectional-fe"

# Tuning parameters
TUNE_SET=mt06.unk
TUNE_SET_NAME=mt06

SEED=`date +%s`
N_STARTING_POINTS=20
NBEST=200
OBJECTIVE=bleu
OPT_FLAGS="-o koehn+cer -s $SEED -F -t $THREADS_DECODE -p $N_STARTING_POINTS"

# Decoding parameters
DECODE_SET=mt05.unk
DECODE_SET_NAME=mt05

