#
# Online parameter tuning with with phrasal-train-tune.sh
#

# General parameters
#
HOST=`hostname -s`
MEM=5g
JAVA_OPTS="-server -ea -Xmx${MEM} -Xms${MEM} -XX:+UseParallelGC -XX:PermSize=256m -XX:MaxPermSize=256m"
DECODER_OPTS="-DSRILM=true -Djava.library.path=/scr/nlp/data/gale3/SRILM-JNI/${HOST}"

# Resource locations
#
REFDIR=/scr/nlp/data/gale/AE-MT-eval-data
SCRIPTDIR=${JAVANLP_HOME}/projects/mt/scripts-private
#CORPUSDIR=/scr/nlp/data/gale3/NIST09/align/merged
CORPUSDIR=/home/rayder441/sandbox/phrasal/corpus
CORPUS_SRC=${CORPUSDIR}/corpus.ar
CORPUS_TGT=${CORPUSDIR}/corpus.en
CORPUS_ALIGN=${CORPUSDIR}/corpus.grow-diag

# Phrase extraction parameters (steps 1 and 5)
#
THREADS_EXTRACT=4
EXTRACTOR_OPTS="-DcustomScores=phi_tf,lex_tf,phi_ft,lex_ft,phrasePenalty,count,uniq"
LINES=90000000
ALIGN=grow-diag
MAX_PHRASE_LEN=7
# Minimum p(e|f) probability for a rule
MIN_PHRASE_SCORE=1e-4

# In how many chunks to split phrase extraction. Setting the
# value to X makes phrase extraction run X times slower,
# though one needs about X times less memory.
# Note: "split" means we split the dev/test-set phrases to score
# into X chunks, and make 1-2 passes over the training data
# for each one of them.
# (if you run out of memory, increase the split value)
SPLIT="-split 2"

EXTRACTORS=edu.stanford.nlp.mt.train.MosesPharoahFeatureExtractor:edu.stanford.nlp.mt.train.CountFeatureExtractor:edu.stanford.nlp.mt.train.LexicalReorderingFeatureExtractor

LO_ARGS="-hierarchicalOrientationModel true -orientationModelType msd2-bidirectional-fe"

# Online tuning parameters
TUNE_MODE=online
TUNE_SET=mt06.unk
TUNE_REF=refs/mt06-debug/ref0
TUNE_SET_NAME=mt06
INITIAL_WTS=phrasal.online.binwts
TUNE_NBEST=500

# Options to pass directly to OnlineTuner
ONLINE_OPTS="-uw -m bleu-cherry"

# Decoding parameters for dev/test set
DECODE_SET=mt05.unk
DECODE_SET_NAME=mt05
NBEST=1