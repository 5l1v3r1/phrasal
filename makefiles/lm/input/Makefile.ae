all: \
	mt.tok.gz \
	fouo.tok.gz \
	LDC2007T07-giga3-xin.tok.gz \
	LDC2007T07-giga3-afp-0.tok.gz

.SECONDARY:

NOCLASS=sed 's/\$$[^ ][^ ]*_(\([^ ][^ ]*\))/\1/g'

#################################
## MT data
#################################

mt.utok.gz: 
	cat /scr/nlp/data/gale2/GALE-P2.5-arabic-fouo/data-v2/enfiles/atb/* | ../scripts/clean_ibm | $(NOCLASS) | gzip > $@
fouo.tok.gz: 
	cat /scr/nlp/data/gale2/GALE-P2.5-arabic-fouo/fouo-v2/enfiles/atb/* | ../scripts/clean_ibm | $(NOCLASS) | gzip > $@

#################################
## Monolingual data
#################################

# Split sets that are too big:
I1=nyt
S1=6500000 
LDC2007T07-giga3-$(I1)-0.tok.gz: LDC2007T07-giga3-$(I1).tok.gz 
	zcat $< | split -l $(S1) -a 1 -d - LDC2007T07-giga3-$(I1)-
	for file in `ls LDC2007T07-giga3-$(I1)-?`; do mv $$file $$file.tok; gzip $$file.tok; done

I2=apw
S2=10000000
LDC2007T07-giga3-$(I2)-0.tok.gz: LDC2007T07-giga3-$(I2).tok.gz 
	zcat $< | split -l $(S2) -a 1 -d - LDC2007T07-giga3-$(I2)-
	for file in `ls LDC2007T07-giga3-$(I2)-?`; do mv $$file $$file.tok; gzip $$file.tok; done

I3=afp
S3=9500000
LDC2007T07-giga3-$(I3)-0.tok.gz: LDC2007T07-giga3-$(I3).tok.gz 
	zcat $< | split -l $(S3) -a 1 -d - LDC2007T07-giga3-$(I3)-
	for file in `ls LDC2007T07-giga3-$(I3)-?`; do mv $$file $$file.tok; gzip $$file.tok; done

# Corrected tokenization:
%.tok.gz: %.utok.gz
	zcat $< | resegment_lm_data 2> $@.log | gzip > $@

# IBM tokenization, plus Stanford postprocessing:
# 1) Produces tokenization as in IBM format:
# 2) Remove bad UTF-8 characters, and remove $num and $email fields.
%.utok.gz: %.gz
	zcat $< | ibm_ae_en_tokenizer 2> logs/$@.log | $(NOCLASS) | gzip > $@

# Extract untokenized texts:
%.gz: ../scripts/%.sh
	$< 2> logs/$@.log | gzip > $@

%.size: %.gz
	zcat $< | wc > $@
